{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Active Learning\n",
    "\n",
    " * Make big data algorithms ask when they're unsure.\n",
    " * Avoid silly questions and ask questions which promise to yield the most information.\n",
    "     - Want to minimize number of requested labels (expensive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Two main approaches:\n",
    " * **Stream-based (online) active learning**: need to decide on the spot whether to request a label for a data point\n",
    " * **Pool-based active learning**: sequentially request point labels from an unlabeled dataset\n",
    " \n",
    "### Simple example\n",
    "Learning a 1D threshold function or a liner threshold function.\n",
    "\n",
    "\\begin{equation}\n",
    "    H = \\left\\{ h : [0, 1] \\mapsto \\{+1, -1\\}, h(x) = \\operatorname{sign}(x - \\tau), \\tau \\in [0, 1] \\right\\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool-based active learning\n",
    " * request labels intelligently until we can infer all remaining labels\n",
    " * efficiency varies (can reduce nr. of requested labels exponentially, or have almost no impact)\n",
    " \n",
    "### Uncertainty sampling\n",
    " * Assign uncertainty score to all points and pick most uncertain example. Widely used heuristic.\n",
    " * SVM: pick point closest to separating hyperplane: $x^{*} = \\operatorname{arg min}_{x_i \\in \\mathcal{U}} | w^T x_i |$\n",
    " * Classifier retrained after every new label (Can we avoid this?).\n",
    " * Complexity to pick $m$ labels: $O\\left( n \\cdot m \\cdot d + \\frac{m^2}{\\epsilon} \\right)$, with $n$ datapoints (need to compute uncertainty score for each), $m$ max requested labels, $d$ dimensions and $\\epsilon$ our error threshold (TODO please confirm).\n",
    "\n",
    "Note: AUROC = Area Under ROC (receiver operating characteristic) Curve; measures the performance of a binary classifier system as its discrimination threshold is varied (i.e. it's big when a classifier has a lot of true positives vs. false positives).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-linear time active learning\n",
    " * Store mappings from hyperplanes (hyperplane query) to close points.\n",
    " * Hyperplane query = give me the closest point(s) to this hyperplane. TODO: why more?\n",
    " * This helps us avoid recomputing uncertainty scores every time we update our model (i.e. the separating hyperplane).\n",
    " * The closer a point's vector is to be perpendicular to the normal $w$, the more likely it is to be close to it. There are exceptions, of course, but most of the time this rule works very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Visualization of a hyperplane query](img/hyperplane-query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how can we hash these queries?\n",
    "\n",
    "Use two random vectors, $u$ and $v$.\n",
    "\n",
    "\\begin{equation}\n",
    "    h_{u, v}(a, b) = [h_u(a), h_v(b)] = [\\operatorname{sign}(u^{T} a), \\operatorname{sign}(v^{T} b)], \\quad u, v \\sim \\mathcal{N}(0, I)\n",
    "\\end{equation}\n",
    "\n",
    "Define a hash family (why?):\n",
    "\n",
    "\\begin{equation}\n",
    "h_{\\mathcal{H}}(z) = \\left\\{\n",
    " \\begin{array}\n",
    "        h_{u, v}(z, z), \\> & \\text{if } z \\text{ is a database point vector} \\\\\n",
    "        h_{u, v}(z, -z), \\> & \\text{if } z \\text{ is a query hyperplane vector} \\\\\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "With this we get an LSH collision probability:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    Pr[h_H(w) & = h_H(x)] = Pr[h_u(w) = h_u(x)] Pr[h_v(-w) = h_v(x)] \\\\\n",
    "    & = \\frac{1}{4} - \\frac{1}{\\pi^2}\\left( \\theta_{x, w} - \\frac{\\pi}{2}\\right)^2\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "(A collision being a query hyperplane vector and another point get put into the same bucket, representing the fact that they are close, and that its label should be requested)\n",
    "\n",
    "For small enough $\\theta_{x, w}$ this is OK but still not great. However, we can use multiple hash functions together in an OR-construction to increase the number of positives. (TODO: not in slides but logical; find reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving active learning\n",
    "\n",
    "Key insight/problem: uncertain $\\nRightarrow$ informative\n",
    "\n",
    "Better to quantify how much information we get from each label, rather than just how uncertain it is.\n",
    "\n",
    "### Version space\n",
    "A **version space** is a set of all classifiers consistent with the current data.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{V}(D) = \\{ w : \\forall \\> (x, y) \\in D, \\operatorname{sign}(w^Tx) = y \\}\n",
    "\\end{equation}\n",
    "\n",
    "Note: this does not account for noisy data.\n",
    "\n",
    "In an SVM case, the original version space could be the whole $l_2$-norm ball of radius $\\frac{1}{\\sqrt{\\lambda}}$.\n",
    "\n",
    "We want to always request a label for the point which will make our version space shrink the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant version space\n",
    "\n",
    "A **relevant version space**, given a pool of unlabeled points, is the set of possible labeling consistent with the data.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\mathcal{V}}(D; U) = \\left\\{ h: U \\rightarrow \\{+1, -1\\} : \\exists w \\in \\mathcal{V}(D) : \\forall \\> x \\in U, \\operatorname{sign}(w^Tx) = h(x) \\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "We use this to conduct a *generalized binary search* to find the most informative point.\n",
    "\n",
    "$v^{+}(x)$ - how many elemenents we would have in the relevant version space if x were labelled +.\n",
    "$v^{-}(x)$ - same, but if x were labelled -.\n",
    "Pick $x$ where the minimum possible change $\\min{(v^{-}(x), v^{+}(x))}$ is the largest. This is the x which, regardless of what label it will get, will shrink the relevant version space the most (\"balanced\" split). (TODO: clarify)\n",
    "\n",
    "In other words for each possible label (+ or -) of an uncertain point, calculate resulting SVMs with margings $m^{+}$ and $m^{-}$. Pick point which produces most \"balanced\" difference between margins:\n",
    "\n",
    " * Max-min margin: $x_t = \\operatorname{arg max}_x \\left\\{ \\min \\{ m_x^-, m_x^+ \\} \\right\\}$ (used in generalized binary search (GBS) example)\n",
    " * Ratio margin: $x_t = \\operatorname{arg max}_x \\left\\{ \\min \\left\\{ \\frac{m_x^-}{m_x^+}, \\frac{m_x^+}{m_x^-} \\right\\} \\right\\}$\n",
    " \n",
    "Wait, \"calculate resulting SVM**s**\"? Isn't that expensive?\n",
    "\n",
    "It is. Optimal max-min margins and ratio margins are expensive to compute. But there exist some practical tricks:\n",
    "\n",
    " * Only score and pick from *small random subsample* of data\n",
    " * Only use informativeness at first (e.g. first 10 examples), then switch to (faster) uncertainty sampling\n",
    " * Occasionally \"cheat\" and pick points *uniformly at random*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with noise\n",
    "\n",
    "Thus far, we assumed there was **no noise**. How to deal with noise?\n",
    " \n",
    " * In practice, it doesn't matter (SVM + slack variables)\n",
    " * In theory, the analysis is **much harder**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open questions\n",
    " * Uncertainty sampling for SVMs: What about kernelized SVMs? Can you still tell what point(s) are closest to the decision boundary (easily)? (Note: just picking the smallest kernel function value between all available training points and the new one doesn't work.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
