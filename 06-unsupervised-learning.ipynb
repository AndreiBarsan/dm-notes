{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering** (and outlier detection) and dimension reduction. Focus on former in this unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points are represented in high-dim Euclidean spaces or any metric spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of clustering\n",
    "\n",
    "### Hierarchical clustering\n",
    "Build a tree representing distances among the data points.\n",
    "*Examples:* single-, average-linkage **agglomerative clustering**.\n",
    "\n",
    "### Partitional approaches\n",
    "Define and optimize an objective function defined over partitions.\n",
    "TODO: What are partitions?\n",
    "*Examples:* spectral clustering, graph-cut based approaches.\n",
    "\n",
    "### Model-based approaches (main focus)\n",
    "Maintain cluster \"models\" and infer cluster membership.\n",
    "Viewed as the \"standard\" clustering methods.\n",
    "*Examples:* k-means, Gaussian mixture models (GMMs), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The k-means problem\n",
    " * Points in Euclidean space, $x_i \\in \\mathbb{R}^d$.\n",
    " * Clusters as centers $\\mu_j \\in \\mathbb{R}^d$.\n",
    " * Each point assigned to closest center.\n",
    " * **Goal**: pick centers to minimize average squared distance:\n",
    " \n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "L(\\mu) & = L(\\mu_1, \\dots, \\mu_k) = \\sum_{i = 1}^{N} \\min_{j} \\| x_i - \\mu_j \\|_2^2 \\\\\n",
    "\\mu^{*} & = \\arg \\min_{\\mu} L(\\mu)\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "NP-hard to solve, so we use **Lloyd's heuristic**, commonly (though not entirely accurately) referred to as the k-means algorithm.\n",
    "\n",
    "The algorithm:\n",
    "\n",
    "* Initialize cluster centers (randomly or in a smarter way): $\\mu^{(0)} = [\\mu_1^{(0)}, \\dots, \\mu_k^{(0)} ]$\n",
    "* Assign every point to closest cluster: $z_i = \\arg \\min_{j} \\| x_i - \\mu_j^{t - 1} \\|_2^2$\n",
    "* Update cluster centers to be at the center of the newly updated cluster: $\\mu_j^{(t)} = \\frac{1}{n_j} \\sum_{i:z_i = j} x_i$\n",
    "* Repeat until convergence (e.g. minimum cluster center movement threshold).\n",
    "\n",
    "### Properties\n",
    " * Guaranteed (can be shown) to *monotonically decrease average squared distance* in each iteration: $L(\\mu^{t+1}) \\le L(\\mu^{t})$\n",
    " * Converges to *local* optimum\n",
    " * $O(nkd)$ per iteration ($n$ elements, $k$ clusters, $d$ dimensions); have to process entire data set in every iteration, so difficult to parallelize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up k-means\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
