{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data mining?\n",
    " * Semi-automatic procedures to find general and useful patterns in large data sets.\n",
    "\n",
    "## Applications\n",
    " * **Approximate retrieval**: Finding similar elements (similar songs, image search, plagiarism detection, copyright protection, etc.) in giant datasets\n",
    " * **Supervised learning**, such as large scale classification (of user behavior, of images, of text, etc.) and regression\n",
    " * **Unsupervised learning**, such as large scale clustering (search for groups of similar users, images, songs, articles, etc.) and dimension reduction\n",
    " * **Recommender systems** (bandit algorithms ($\\epsilon$-greedy, UCB1, LinUCB, Hybrid LinUCB, etc.) and their applications in fields such as news article recommendation and adverting)\n",
    " * Others (monitoring transients in astronomy, spam filtering, fraud detection, machine translation, six degrees of ~~Kevin Bacon~~ separation etc.)\n",
    " \n",
    " \n",
    "## Scale\n",
    " * Example: 10-100 TB of data per sky survey (astronomy)\n",
    " * Archive sizes measured in **petabytes**\n",
    " * Real-time data flows (e.g. computing trends in social network)\n",
    " * Data sources\n",
    "     - science\n",
    "     - commercial/civil/engineering\n",
    "     - security/intelligence/defense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical aspects\n",
    " * Want to keep data in main memory as much as possible (faster)\n",
    " * If data don't fit in the main memory, we have to access it in a streaming fashion. Random access would be much too expensive, so we have to adapt our algorithms in order to learn from streaming data.\n",
    " * Want *real-time analytics*\n",
    " * Want real-time synthesis\n",
    " * Want to leverage large-scale parallelism (across entire data centers)\n",
    " * Data quality often sucks (missing elements, missing elements represented as seemingly-present elements (null vs. \"\" vs. 0 vs. \"\\0\" vs. undefined, etc.), inconsistent schema, etc.)\n",
    " * Need to respect users' privacy (control direct access to data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not covered\n",
    " * Systems issues (databases, data center management, etc.)\n",
    " * Specialized data structures\n",
    " * Domain specific algorithms\n",
    "     - see **Information retrieval** course for more text-specific elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce\n",
    " * Works well with commodity hardware in data centers (DCs)\n",
    " * Failure-tolerant (redundancy over DC)\n",
    " * Works with distributed file systems (e.g. Google GFS, HDFS, etc.), which are optimized for durability, frequent reads and appends, but rare updates\n",
    " * `map(key, value)` and `reduce(key, values)` (bread and butter; other operations exist); the default shuffler does a lot of the grunt work!\n",
    " * **Partitions** the input data, **schedules** program execution across a set of machines, handles machine **failures**, and manages inter-machine **communication**\n",
    " * A job's output is often another job's input; many tools support multi-stage pipelines natively (Cascading, Scalding, Spark, MS DryadLINQ, etc.)\n",
    " * Stragglers (last few remaining reducers) $\\implies$ spawn multiple copies of job and take the result of whoever finishes first\n",
    " * Hadoop is the most common MapReduce implementation; relies a lot on disk access $\\implies$ slow; Spark offers massive speedups by relying less on disk access\n",
    "\n",
    "Trick to compute variance in one pass: use formula based on expectation ($\\mathbb{V}ar(X) = \\hat{\\mathbb{E}}[X^2] - \\hat{\\mathbb{E}}[X]^2$).\n",
    "\n",
    "GPGPUs can also offer massive speed-ups when used right. They are not covered in this course, but are very widely used for algorithms requiring heavy number-crunching (many vector/matrix operations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Statistical limits and Bonferroni's Principle\n",
    "### Context\n",
    " * 2002, Post 9/11 USA, The Patriot Act $\\implies$ the *Total Information Awareness* project (eventually killed by Congress, allegedly)\n",
    " * Problem: when viewing so much data, almost everything could be seen as suspicious. It depends just on how narrowly you define the activities that you look for.\n",
    " * One can find certain event types or patterns even in completely random data\n",
    " * Avoid this fallacy using *Bonferroni's principle*\n",
    " * See first chapter in textbook for more details [CITE](#cite-rajaraman2012mining)\n",
    " \n",
    "### The principle\n",
    " * first calculate the $\\mathbb{E}[\\text{nr. occurrences}]$, assuming the data is purely random\n",
    " * if this number is significantly larger than the actual number of instances we hope to find, then any result would be bogus\n",
    "\n",
    "### An example\n",
    " * Assume: \n",
    "     - evil doers exist, and gather periodically at a hotel\n",
    "     - 1 billion suspects\n",
    "     - everyone goes to the hotel once every 100 days\n",
    "     - each hotel has 100 spots; there are 100000 hotels\n",
    "     - will examine hotel records for 1000 days\n",
    " * Seek:\n",
    "     - pairs of people who were both at the same hotel on two different days (the two hotels don't have to be the same on the different days)\n",
    " * Apply principle:\n",
    "     - assume no evil-doers (\"random\" data)\n",
    "     - $P(\\text{visit a hotel}) = 0.01$\n",
    "     - $P(\\text{2 people visit a hotel}) = (0.01)^2 = 0.0001 = 10^{-4}$\n",
    "     - $P(\\text{2 people same hotel}) = P(\\text{2 people visit a hotel}) \\times \\frac{1}{\\text{#hotels}} = 10^{-4} \\times 10^{-5} = 10^{-9}$\n",
    "     - $P(\\text{2 people same hotel on 2 days}) = \\left( 10^{-9} \\right)^{2} = 10^{-18}$\n",
    "     - Approximate the number of different events (#hotel pairs times #person pairs). It's $5 \\times 10^{17} \\times 5 \\times 10^5$.\n",
    "     - #suspicious events is the above number times the probability such an event is something we're looking for.\n",
    "     - Our result is 250k suspicious events. Under the assumption that there are **no** terrorists.\n",
    "     - If there really are 10 pairs of evil-doers, the police would still need to investigate \\~500k people first\n",
    " * Conclusion:\n",
    "     - we are limited in our ability to mine data for features that are not sufficiently *rare* in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous\n",
    " * Power law: a linear relationship between the logarithms of the variables\n",
    " * Forms: $\\log{y} = b + a\\log{x} \\iff y = cx^a$, for some constants $a$, $b$, and $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References\n",
    "\n",
    "<!--bibtex\n",
    "@book{rajaraman2012mining,\n",
    "  title={Mining of massive datasets},\n",
    "  author={Rajaraman, Anand and Ullman, Jeffrey D and Ullman, Jeffrey David and Ullman, Jeffrey David},\n",
    "  volume={77},\n",
    "  year={2012},\n",
    "  publisher={Cambridge University Press Cambridge}\n",
    "}\n",
    "\n",
    "-->\n",
    "\n",
    "**TODO** make this work nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
