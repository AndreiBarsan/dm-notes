{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series 3, Online Convex Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.linalg import norm\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure consistency across runs.\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = np.genfromtxt('data/Xtrain.csv', delimiter=',')\n",
    "Ytrain = np.genfromtxt('data/Ytrain.csv', delimiter=',', dtype='int8')\n",
    "Xtest = np.genfromtxt('data/Xtest.csv', delimiter=',')\n",
    "Ytest = np.genfromtxt('data/Ytest.csv', delimiter=',', dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute_data(x, y):\n",
    "    \"\"\"Shuffles both numpy arrays in unison.\"\"\"\n",
    "    perm = np.random.permutation(x.shape[0])\n",
    "    return x[perm, :], y[perm]\n",
    "\n",
    "Xtrain, Ytrain = permute_data(Xtrain, Ytrain)\n",
    "Xtest, Ytest = permute_data(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "class OnlineSVMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **params):\n",
    "        self.w = None\n",
    "        self.lbd = 1.0\n",
    "        self.set_params(**params)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.w = np.zeros(X.shape[1], dtype='float64')\n",
    "        \n",
    "        for t, (x, label) in enumerate(zip(X, y)):\n",
    "            eta = 1.0 / np.sqrt(t + 1)\n",
    "            hinge = label * np.inner(self.w, x)\n",
    "            if hinge < 1:\n",
    "                self.w = self.w + eta * label * x\n",
    "                self.project()\n",
    "\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def project(self):\n",
    "        sqrt_lambda = np.sqrt(self.lbd)\n",
    "        w_norm = norm(self.w)\n",
    "        regularizer = 1.0 / (sqrt_lambda * w_norm)\n",
    "        self.w *= min(1.0, regularizer)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        signs = np.sign(np.inner(self.w, X))\n",
    "        signs[signs == 0] = -1\n",
    "        return signs.astype('int8')\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"lbd\": self.lbd}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "# check_estimator(OnlineSVMClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls = OnlineSVMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.936115\n",
      "Best score params: {'lbd': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'lbd': [0.001, 0.005, 0.0075, 0.01, 0.0125, 0.05, 0.1]\n",
    "}\n",
    "gs = GridSearchCV(cls, parameters)\n",
    "gs_result = gs.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(\"Best score: %f\" % gs_result.best_score_)\n",
    "print(\"Best score params: %s\" % gs_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.937240\n",
      "Best score params: {'lbd': 0.011353224786015938}\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "rs_params = {\n",
    "    \"lbd\": stats.uniform(loc=0.001, scale=0.099)\n",
    "}\n",
    "rs_n_iter = 100\n",
    "rs = RandomizedSearchCV(cls, rs_params, rs_n_iter, n_jobs=1)\n",
    "rs_result = rs.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(\"Best score: %f\" % rs_result.best_score_)\n",
    "print(\"Best score params: %s\" % rs_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test score: 0.955836\n"
     ]
    }
   ],
   "source": [
    "rs_best = rs_result.best_estimator_\n",
    "\n",
    "test_score = rs_best.score(Xtest, Ytest)\n",
    "print(\"Best test score: %f\" % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training samples: 0.468980\n",
      "1 training samples: 0.468980\n",
      "2 training samples: 0.468980\n",
      "3 training samples: 0.531020\n",
      "4 training samples: 0.531020\n",
      "5 training samples: 0.472135\n",
      "7 training samples: 0.555205\n",
      "10 training samples: 0.555205\n",
      "13 training samples: 0.740799\n",
      "18 training samples: 0.669295\n",
      "25 training samples: 0.741851\n",
      "35 training samples: 0.584122\n",
      "48 training samples: 0.669821\n",
      "66 training samples: 0.701367\n",
      "91 training samples: 0.855941\n",
      "126 training samples: 0.904837\n",
      "174 training samples: 0.772345\n",
      "241 training samples: 0.906414\n",
      "332 training samples: 0.901157\n",
      "459 training samples: 0.886961\n",
      "634 training samples: 0.917455\n",
      "875 training samples: 0.943218\n",
      "1208 training samples: 0.937960\n",
      "1668 training samples: 0.945321\n",
      "2302 training samples: 0.954784\n",
      "3179 training samples: 0.948475\n",
      "4389 training samples: 0.949001\n",
      "6060 training samples: 0.944269\n",
      "8367 training samples: 0.942166\n",
      "11552 training samples: 0.954784\n"
     ]
    }
   ],
   "source": [
    "test_count = Xtrain.shape[0]\n",
    "\n",
    "cls = OnlineSVMClassifier(lbd=0.11)\n",
    "\n",
    "# TODO(andrei) Plot this shit.\n",
    "# TODO(andrei) Logistic regression with tonsa comments.\n",
    "# TODO(andrei) Try to get a general idea of how they implemented the projection to the L1-ball (i.e. LASSO-like).\n",
    "for amount in list(np.round((np.logspace(0, np.log10(test_count), 30)))):\n",
    "    Xsubsample = Xtrain[:int(amount),:]\n",
    "    Ysubsample = Ytrain[:int(amount)]\n",
    "    cls.fit(Xsubsample, Ysubsample)\n",
    "    print(\"%d training samples: %f\" % (amount, cls.score(Xtest, Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
